{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [0 0], Predicted Output: 0\n",
      "Input: [0 1], Predicted Output: 1\n",
      "Input: [1 0], Predicted Output: 1\n",
      "Input: [1 1], Predicted Output: 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, input_size, learning_rate=0.01, epochs=100):\n",
    "        self.input_size = input_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.weights = np.random.randn(input_size)\n",
    "        self.bias = np.random.randn()\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        # Summation of weighted inputs and bias\n",
    "        summation = np.dot(inputs, self.weights) + self.bias\n",
    "        # Activation function (here, using step function)\n",
    "        return 1 if summation > 0 else 0\n",
    "\n",
    "    def train(self, training_inputs, labels):\n",
    "        for epoch in range(self.epochs):\n",
    "            for inputs, label in zip(training_inputs, labels):\n",
    "                prediction = self.predict(inputs)\n",
    "                # Update weights and bias based on prediction error\n",
    "                self.weights += self.learning_rate * (label - prediction) * inputs\n",
    "                self.bias += self.learning_rate * (label - prediction)\n",
    "\n",
    "# Training data (OR gate)\n",
    "training_inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "labels = np.array([0, 1, 1, 1])\n",
    "\n",
    "# Create a perceptron with 2 inputs\n",
    "perceptron = Perceptron(input_size=2)\n",
    "\n",
    "# Train the perceptron\n",
    "perceptron.train(training_inputs, labels)\n",
    "\n",
    "# Test the trained perceptron\n",
    "test_inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "for inputs in test_inputs:\n",
    "    print(f\"Input: {inputs}, Predicted Output: {perceptron.predict(inputs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 3s 0us/step\n",
      "Training model with ReLU activation function...\n",
      "Test accuracy with ReLU activation function: 0.9761000275611877\n",
      "Training model with Sigmoid activation function...\n",
      "Test accuracy with Sigmoid activation function: 0.9711999893188477\n",
      "Training model with Tanh activation function...\n",
      "Test accuracy with Tanh activation function: 0.9775999784469604\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.activations import relu, sigmoid, tanh\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load and preprocess the MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "train_labels, test_labels = to_categorical(train_labels), to_categorical(test_labels)\n",
    "\n",
    "# Define a function to build a model with specified activation function\n",
    "def build_model(activation_func):\n",
    "    model = Sequential([\n",
    "        Flatten(input_shape=(28, 28)),\n",
    "        Dense(128, activation=activation_func),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# List of activation functions to compare\n",
    "activation_functions = [relu, sigmoid, tanh]\n",
    "activation_names = ['ReLU', 'Sigmoid', 'Tanh']\n",
    "\n",
    "# Train and evaluate models with different activation functions\n",
    "for activation_func, activation_name in zip(activation_functions, activation_names):\n",
    "    print(f\"Training model with {activation_name} activation function...\")\n",
    "    model = build_model(activation_func)\n",
    "    model.fit(train_images, train_labels, epochs=5, verbose=0)\n",
    "    _, test_accuracy = model.evaluate(test_images, test_labels, verbose=0)\n",
    "    print(f\"Test accuracy with {activation_name} activation function: {test_accuracy}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
